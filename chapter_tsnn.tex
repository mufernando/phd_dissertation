\section{Introduction}

% Genetic data carries information about past evolutionary events
% Kinds of things that can be inferred from genetic data
% With the increase in population genomic data, there is demand for powerful computational tools that can use the big data
Processes like mutation, recombination, population size changes and selection leave footprints on genetic variation.
A major goal of population genetics has been to invert this relationship and infer past, unobserved evolutionary events from genetic variation data \citep{schraiber_methods_2015}.
However, with the dramatic increase in our ability to generate whole-genome data,
there is a need for more efficient inference methods that can scale well to over tens of thousands of individuals.

% How has inference been done traditionally?
% Thinking about how processes impact trees, then translating that into summary statistics that can be computed from genetic data.
% These stats do lose some information, however.
Although our interest is to infer evolutionary processes from population genetic data,
it is usually simpler to first think about the effects of evolutionary processes on the underlying genealogies \citep{wakely_coalescent_2016}.
Genealogies are the tree-like structures that describe the relationships between samples of a population.
Different processes impact genealogies in different ways.
Recent contractions in population sizes will lead to trees which have shorter branches near the tips (due to an increase in the rate of coalescence caused by the contraction), for example.
A tree can then be used to describe patterns of genetic variation such as the site frequency spectrum (SFS).
The SFS describes the distrubution of allele frequencies across sites in the genome,
and it can be used to infer demographic histories from natural populations \citep{gutenkunst_inferring_2009, schraiber_methods_2015}.
In the example of a recent population size reduction,
we would expect an excess of derived alleles with intermediate and high frequencies,
because most of the coalescences will have occured in the recent past leading to big internal branches where most of the mutations would fall.


% Inference can be done in by computing likelihoods, but these are tricky, specially for some summary stats.
% One can do inference on multiple stats at once using simulation-based inference.
Statistics that summarize genetic variation data, such as the SFS, cannot capture all aspects of variation in genetic data that are informative of the underlying processes.
Some studies have circumvented this by using multiple summary statistics either in a composite likelihood framework or with likelihood-free methods \citep{nielsen_genomic_2005, degiorgio_sweepfinder2_2016, sheehan_deep_2016, caldas_inference_2022, pavlidis_sweed_2013}.
Writing and computing likelihoods in complex evolutionary scenarios can be challenging.
Likelihood-free methods (\eg ABC or machine learning) have gained some popularity in population genetics,
followed by advances in evolutionary genetics simulation software that can be used to generate labeled training data \citep{haller_tree-sequence_2019, kelleher_efficient_2016, ralph_efficiently_2020}.
%Some examples of applications: Sheehan PLoS CompBio, SHIC, Pavlidis, Michael DiGiorgio, etc. 

% Traditional likelihood-free methods have been using genotype matrices or summary stats matrices for inference.
% CNNs on these matrices do well, but there is a problem with scaling (wrt to sampling and genome size).
Many of the likelihood-free methods model how evolutionary processes impact summary statistics along chromosomes (or windows) or raw genotype matrices \citep{schrider_shic_2016, flagel_unreasonable_2019, sheehan_deep_2016}.
When dealing with large chromosomes, these have to be split into chunks for computational tractability;
that is, when the number of loci grows it becomes computationally infeasible to apply these methods over large matrices.
In the case of summary statistics, it is possible to compute them over larger windows to capture variation along full chromosomes,
but this comes at the cost of losing granularity and some evolutionary signals can be quite localized \citep{caldas_inference_2022}.

% An alternative data structure, the whole genome genealogies, can be leveraged for evol inference.
% This structure is way more compact and the data is restructured in such a way that can facilitate learning.
An alternative data structure, whole-genome genealogies, can be leveraged for evolutionary inference.
Genotype matrices are redundant due to shared ancestry, that is related samples will share the same alleles at many of the variant sites.
Trees, which describe the relationships between samples from a population, provide a more efficient way of encoding genetic data.
In recombining genomes, there is not a single tree, but rather a collection of trees (which are autocorrelated) along chromosomes.
Recent work has made it possible to infer whole-genome genealogies for thousands of individuals \citep{speidel_inferring_2021, kelleher_inferring_2019, zhang_biobank-scale_2023}.

Benefits of these tree sequences go beyond computational efficiency and scallability, however.
Trees can perfectly encode evolutionary processes and event and can bring us closer to the processes that we are interested in inferring \citep{rasmussen_genome-wide_2014}.
Indeed, much of population genetics inference starts from understanding how a particular process impacts the underlying genealogies.
More than that, trees bring a time dimension which can be helpful in inferring events localized in time (\eg migration pulses, past selective sweeps, etc.) \citep{speidel_inferring_2021}.

Here, we present a new method that leverages these whole-genome genealogies for evolutionary inference.
Our main goal is to develop an architecture that can efficiently use genealogies for inference at different levels.
We test our method on two tasks: (i) dating mutations and (ii) inferring parameters from a given demographic model.
Our approach performs well on both tasks, even outperforming current state-of-the-art methods.
The new method presented here highlights the utility of whole-genome genealogies in population genetic inference.

% Here, we aim to develop an architecture that uses these whole genome genealogies for inference.

\section{Methods} \label{sec:methods}

\subsection{Model}
Taking inspiration from the graph neural network literature,
we developed a family of neural networks that can take whole-genome genealogies as input.
In summary, we obtain a lower dimension representation of these genealogies by passing messages between nodes.
We start with an initialized embedding for nodes, and
then we use an update scheme that takes an edge and updates the embedding of both child and parent nodes.
Because the flow of information is structured from parent to child and from left-to-right,
we hoped this neural network would learn a better representation of a tree sequence than a more naive approach,
such as a simpler graph neural network.
The node embeddings can then be aggregated to obtain edge (and mutation) embeddings or a tree sequence level embedding.

First, we define a module for obtaining node embeddings.
We randomly (or arbitrarily) initialize a vector with node features $H$ of dimension number of nodes by number of node features.
From a given tree sequence, we also compute a vector $E$ of edge features of dimension number of edges by number of edge features.
We define two edge features: the span (width in number of base pairs that an edge spans, scaled by the mutation rate) and edge length (the difference between the parent and child node times).
We traverse the tree sequence over edge differences (from letft-to-right, and optionally from right-to-left), and
with each edge addition, we build a message that is used to update the node features $H$.
The message for the edge that links the parent node $p$ to the child node $c$ is 
$$ m_{pc} = e_{pc} \mathbin\Vert (h_p \mathbin\Vert h_c)$$
where $e_{pc}$ is the row of $E$ for the edge $p-c$, and $h_p$ and $h_c$ are the rows of $H$ for nodes $p$ and $c$.
$h_p$ and $h_c$ are then updated with a Gated Recurrent Unit cell, such that

$$ h^{\mathrm{out}}_p \mathbin\Vert h^{\mathrm{out}}_c = \mathrm{GRU}(m_{pc}, h_p \mathbin\Vert h_c)$$

The node embedding module above can be used in different neural network architectures to infer parameters at different levels.




\subsection{Tasks}
To evaluate the utility of tsNN in population genetics inference, we designed two tasks with inference at different levels.
First, we dated mutations in a tree sequence given a demographic model.
Second, we inferred parameters from a given demographic model.
These tasks allow us to showcase how node embeddings can be aggregated at different levels (mutation and tree sequence) for different evolutionary questions.

\subsection{Simulations}



\section{Results and discussion}

\subsection{Inferring mutation times}

\subsection{Inferring demographic model parameters}

\section{Conclusion}
